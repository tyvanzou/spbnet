epoch: 200
device: [0, 1, 2, 3]
batch_size: 32
accumulate_grad_batches: 8

resume: ~

useBasis: true
useCharge: false
useMoc: false

# root_dir: ./data/pretrain
modal_folder: "."
id_prop: vftopo
log_dir: ./lightning_logs/pretrain

vfp: 1
tc: 1
agc: 1

accelerator: gpu
strategy: ddp_find_unused_parameters_true
precision: 16-mixed
log_every_n_steps: 10

limit_train_batches: 1.0 # for test
